---
title: "Machine Learning to predict funds outperformance in crisis periods"
output: html_notebook
---

# Packages

```{r, message=FALSE, warning=FALSE}
library(reticulate)
library(tidyverse)
library(xts)
library(PerformanceAnalytics)
library(lubridate)
library(caret)

`%ni%` <- Negate(`%in%`)
```

# Import Data

Index return (IBX) and Risk free return (CDI):

```{r}
ind <- read.csv('indice.csv')
ind$Data <- as.Date(ind$Data)

rf <- read.csv('rf.csv')
rf$Data <- as.Date(rf$Data)

ind_rf <- ind %>% mutate(rf$Risk_free) %>% set_names('Data', 'ret_ibx', 'ret_rf')

rm(ind, rf)
```

Funds information:

```{r}
daily_data <- readRDS('dados_tratados_diarios.rds')
names(daily_data) <- c('capt_liq', 'capt', 'cota', 'n_cotistas', 'patrim_liq', 'resg', 'tx_adm')
```

```{r}
cadastral_info <- readRDS('dados_cadastrais.rds')

cadastral_info <- cadastral_info %>% 
  dplyr::select(codigo, invest_qualificado, alavancado, data_inicio, prazo_conv_resg, prazo_pag_resg, aplic_min_inic, forma_condominio, fundo_cotas, fundo_exclusivo, data_inicio, data_fim)

cadastral_info$invest_qualificado <- ifelse(cadastral_info$invest_qualificado == 'N達o', 0, 1)

cadastral_info$alavancado <- ifelse(cadastral_info$alavancado == 'N達o', 0, 1)

cadastral_info$prazo_conv_resg <- as.numeric(str_sub(cadastral_info$prazo_conv_resg, -3, -1))
cadastral_info$prazo_pag_resg <- as.numeric(str_sub(cadastral_info$prazo_pag_resg, -3, -1))
cadastral_info$prazo_receb_resg <- cadastral_info$prazo_conv_resg + cadastral_info$prazo_pag_resg

cadastral_info$aplic_min_inic <- as.numeric(cadastral_info$aplic_min_inic)

cadastral_info$forma_condominio <- ifelse(cadastral_info$forma_condominio == 'Fechado', 0, 1)

cadastral_info$fundo_cotas <- ifelse(cadastral_info$fundo_cotas == 'N達o', 0, 1)

cadastral_info$fundo_exclusivo <- ifelse(cadastral_info$fundo_exclusivo == 'N達o', 0, 1)

diff_cadastral_daily <- setdiff(cadastral_info$codigo, colnames(daily_data[['cota']]))
cadastral_info <- cadastral_info %>% dplyr::filter(codigo %ni% diff_cadastral_daily)
```


# Funds selection

* The fund needs to be active for at least 12 months;
* During these 12 months, the fund needs to have data for at least 80% of the days when the market was open;
* The fund needs to have at least R$5.000.000 of Assets Under Management to avoid the incubation bias.

```{r}
# 2019-02-19 ATE 2020-02-19
get_funds_eleg <- function(start_pre_date, end_pre_date){
  # First restriction
  funds_eleg <- cadastral_info %>% dplyr::filter(data_inicio <= start_pre_date & (data_fim >= end_pre_date | is.na(data_fim))) %>% dplyr::select(codigo)
  
  # Second restriction
  funds_eleg <- daily_data[['cota']] %>% dplyr::filter(Data >= start_pre_date & Data <= end_pre_date) %>%
    dplyr::select(all_of(funds_eleg$codigo)) %>% 
    dplyr::select_if(~!any(is.na(.))) %>%
    dplyr::select_if(function(x) sum(x != 0) %ni% 0:(12*21*0.20))
  
  funds_eleg <- colnames(funds_eleg)
  
  return(funds_eleg)
}

```

# Feature Creation

## Returns Statistics

```{r}
get_stat_ret <- function(ret_port, ind, rf) {
  
  # Cumulative Return
  ret_period <- function(ret) {
    prod(ret + 1)^(252 / length(ret)) - 1
  }
  
  # CAPM
  regres <- lm(I(ret_port - rf) ~ I(ind - rf))
  # Get regression coefficients
  regres_coef <- summary(regres)$coefficients
  
  alpha <- (regres_coef[1, 1] + 1) ^ 252 - 1
  beta <- regres_coef[2, 1]
  
  # Porftolio cumulative return
  cumulative_ret <- ret_period(ret_port)
  
  # Portfolio volatility
  vol <- sd(ret_port) * sqrt(252)
  
  # Israelsen Sharpe Ratio and Information Ratio (ttps://doi.org/10.1057/palgrave.jam.2240158)
  ER <- mean(ret_port - rf)
  SD <- sd(ret_port - rf)
  MSR <- ER / (SD ^ (ER / abs(ER))) # Modified SR
  
  ER <- mean(ret_port - ind)
  SD <- sd(ret_port - ind)
  MIR <- ER / (SD ^ (ER / abs(ER))) # Modified IR
  
  # CVaR
  cvar <- CVaR(ret_port, method = 'historical')
  
  results <- data.frame(
    cumulative_ret, vol, MSR, MIR,
    beta, alpha, cvar
  )
  
  return(results)
}
```

```{r}
get_funds_stat <- function(start_pre_date, end_pre_date, funds_eleg){
  # Return Statistics
  funds_returns <- daily_data[['cota']] %>% dplyr::filter(Data >= start_pre_date & Data <= end_pre_date) %>%
  dplyr::select(all_of(funds_eleg)) 

  ind_rf_pre <- ind_rf %>% dplyr::filter(Data >= start_pre_date & Data <= end_pre_date)
  
  funds_stats <- lapply(funds_returns, function(x) get_stat_ret(x, ind_rf_pre$ret_ibx, ind_rf_pre$ret_rf))
  
  funds_stats <- do.call('rbind', funds_stats)
  
  # Assets Under Manegment
  funds_aum <- daily_data[['patrim_liq']] %>% dplyr::filter(Data >= start_pre_date & Data <= end_pre_date) %>%
  dplyr::select(all_of(funds_eleg)) 
  
  funds_aum <- lapply(funds_aum, function(x) mean(x, na.rm = TRUE))
  
  funds_aum <- as.data.frame(do.call('rbind', funds_aum)) %>% set_names('aum')
  
  # Inflow
  funds_inflow <- daily_data[['capt']] %>% dplyr::filter(Data >= start_pre_date & Data <= end_pre_date) %>%
  dplyr::select(all_of(funds_eleg)) 
  
  funds_inflow <- lapply(funds_inflow, function(x) sum(x, na.rm = TRUE))
  
  funds_inflow <- as.data.frame(do.call('rbind', funds_inflow)) %>% set_names('inflow')
  
  # Outflow
  funds_outflow <- daily_data[['resg']] %>% dplyr::filter(Data >= start_pre_date & Data <= end_pre_date) %>%
  dplyr::select(all_of(funds_eleg)) 
  
  funds_outflow <- lapply(funds_outflow, function(x) sum(x, na.rm = TRUE))
  
  funds_outflow <- as.data.frame(do.call('rbind', funds_outflow)) %>% set_names('outflow')
  
  # Number of shareholders
  funds_share_hold <- daily_data[['n_cotistas']] %>% dplyr::filter(Data >= start_pre_date & Data <= end_pre_date) %>%
  dplyr::select(all_of(funds_eleg)) 
  
  funds_share_hold <- lapply(funds_share_hold, function(x) mean(x, na.rm = TRUE))
  
  funds_share_hold <- as.data.frame(do.call('rbind', funds_share_hold)) %>% set_names('shareholders')
  
  # Join all data frames
  merge.all <- function(x, ..., by = "row.names") {
    L <- list(...)
    for (i in seq_along(L)) {
      x <- merge(x, L[[i]], by = by)
      rownames(x) <- x$Row.names
      x$Row.names <- NULL
    }
    return(x)
  }
  
  funds_stats <- merge.all(funds_stats, funds_aum, funds_inflow, funds_outflow, funds_share_hold)
  
  return(funds_stats)
}

```

# Dependent Variable (0 or 1)

```{r}
get_dependent_var <- function(start_eval_date, end_eval_date, funds_eleg){
  funds_returns_eval <- daily_data[['cota']] %>% dplyr::filter(Data > start_eval_date & Data <= end_eval_date) %>%
    dplyr::select(all_of(funds_eleg)) 
  
  ind_rf_eval <- ind_rf %>% dplyr::filter(Data > start_eval_date & Data <= end_eval_date)
  
  funds_stats_eval <- lapply(funds_returns_eval, function(x) prod(1 + (x - ind_rf_eval$ret_ibx), na.rm = TRUE) - 1)
  
  funds_stats_eval <- do.call('c', funds_stats_eval)
  
  funds_stats_eval <- as.data.frame(ifelse(funds_stats_eval > 0, 1, 0)) %>% set_names('ret_eval')
  
  return(funds_stats_eval)
}
```

# Wrapper Function

```{r}
get_final_df <- function(start_pre_date, end_pre_date, start_eval_date, end_eval_date){
  funds_eleg <- get_funds_eleg(start_pre_date, end_pre_date)

  funds_ret_stat <- get_funds_stat(start_pre_date, end_pre_date, funds_eleg)
  
  funds_cadastral <- cadastral_info %>% dplyr::filter(codigo %in% funds_eleg) %>%
    mutate(idade = time_length(difftime(as.Date(end_pre_date), as.Date(data_inicio)), "years")) %>%
    `rownames<-`(.$codigo) %>%
    dplyr::select(!c(codigo, data_inicio, data_fim, prazo_conv_resg, prazo_pag_resg))
  
  funds_stat_eval <- get_dependent_var(start_eval_date, end_eval_date, funds_eleg)
  
  funds_stat <- merge(funds_stat_eval, funds_ret_stat, by = 0) %>% 
    `rownames<-`(.$Row.names) %>%
    dplyr::select(!Row.names)
  
  funds_stat <- merge(funds_stat, funds_cadastral, by = 0) %>% 
    `rownames<-`(.$Row.names) %>%
    dplyr::select(!Row.names)
  
  return(funds_stat)
}

```

# Get clean data for some periods

```{r, message=FALSE, warning=FALSE}
sixteen_seventeen <- get_final_df('2016-01-01', '2016-12-31', '2017-01-01', '2017-12-31') %>%
  dplyr::select(!c(invest_qualificado, aplic_min_inic)) %>% mutate_at(vars(forma_condominio, fundo_cotas, fundo_exclusivo),~ifelse(is.na(.x), 0, .x)) %>%
  mutate(year = '2017')

seventeen_eighteen <- get_final_df('2017-01-01', '2017-12-31', '2018-01-01', '2018-12-31') %>%
  dplyr::select(!c(invest_qualificado, aplic_min_inic)) %>% mutate_at(vars(forma_condominio, fundo_cotas, fundo_exclusivo),~ifelse(is.na(.x), 0, .x)) %>%
  mutate(year = '2018')

eighteen_nineteen <- get_final_df('2018-01-01', '2018-12-31', '2019-01-01', '2019-12-31') %>%
  dplyr::select(!c(invest_qualificado, aplic_min_inic)) %>% mutate_at(vars(forma_condominio, fundo_cotas, fundo_exclusivo),~ifelse(is.na(.x), 0, .x)) %>%
  mutate(year = '2019')

nineteen_twenty <- get_final_df('2019-01-01', '2019-12-31', '2020-01-01', '2020-12-31') %>%
  dplyr::select(!c(invest_qualificado, aplic_min_inic)) %>% mutate_at(vars(forma_condominio, fundo_cotas, fundo_exclusivo),~ifelse(is.na(.x), 0, .x)) %>%
  mutate(year = '2020')

twenty_twnt_one <- get_final_df('2020-01-01', '2020-12-31', '2021-01-01', '2021-12-31') %>%
  dplyr::select(!c(invest_qualificado, aplic_min_inic)) %>% mutate_at(vars(forma_condominio, fundo_cotas, fundo_exclusivo),~ifelse(is.na(.x), 0, .x)) %>%
  mutate(year = '2021')

five_years <- do.call('rbind', list(sixteen_seventeen, seventeen_eighteen, eighteen_nineteen, nineteen_twenty, twenty_twnt_one))

```

```{r}
rm(cadastral_info, daily_data, ind_rf, diff_cadastral_daily,sixteen_seventeen, seventeen_eighteen, eighteen_nineteen, nineteen_twenty, twenty_twnt_one)
```

```{r}
data <- r_to_py(five_years)

```


```{python}
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

# Evaluate classification
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import f1_score, accuracy_score, mean_squared_error, mean_absolute_error, precision_score

# Lidar com dados desbalanceados
from imblearn.over_sampling import RandomOverSampler

# XGBoost
import xgboost as xgb

from pycaret.classification import *

```

```{python}
data = r.data

data = pd.concat((data,pd.get_dummies(data.year, dtype = 'float64')),1)

data = data.drop(['year'], axis = 1)

```

```{python}
data_out_2021 = data.loc[data['2021'] == 0].drop('2021', axis = 1)
data_2021 = data.loc[data['2021'] == 1].drop('2021', axis = 1)

X_train, y_train = data_out_2021.drop('ret_eval', axis = 1), data_out_2021.ret_eval

X_test, y_test = data_2021.drop('ret_eval', axis = 1), data_2021.ret_eval

```

# Pycaret

```{python}
# setup the dataset
grid = setup(data=data_out_2021, target='ret_eval', session_id=42, n_jobs=1)

# evaluate models and compare models
best_model = compare_models()

regression_results = pull()
```

```{python}
pd.set_option("display.max_rows", None, "display.max_columns", None)

print(regression_results)
```


```{python}
plot_model(best_model, plot='feature')
```

```{python}
pred_holdout  = predict_model(best_model, data = data_2021)

regression_results = pull()
```

```{python}
regression_results
```


# XGBoost

```{python}
model = xgb.XGBClassifier()

model.fit(X_train, y_train)

xgb_pred = model.predict(X_test)

print(classification_report(y_test, xgb_pred))
```

```{python}
cm = confusion_matrix(y_test, xgb_pred)

ConfusionMatrixDisplay(cm).plot(cmap='Blues')
plt.show()
```

