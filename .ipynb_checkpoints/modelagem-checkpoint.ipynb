{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a8ca3e",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d400ef92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f452ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data cleaned in R\n",
    "data = pd.read_csv(\"data_modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43d91a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['codigo', 'dep_var', 'f_r2_1', 'f_r12_2', 'f_st_rev', 'abnormal_ret',\n",
       "       'track_error', 'MIR', 'beta_mercado', 'beta_size', 'beta_value',\n",
       "       'beta_mom', 'alpha', 'cvar', 'aum', 'inflow', 'outflow', 'shareholders',\n",
       "       'alavancado', 'fundo_cotas', 'fundo_exclusivo', 'age', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13749b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>dep_var</th>\n",
       "      <th>f_r2_1</th>\n",
       "      <th>f_r12_2</th>\n",
       "      <th>f_st_rev</th>\n",
       "      <th>abnormal_ret</th>\n",
       "      <th>track_error</th>\n",
       "      <th>MIR</th>\n",
       "      <th>beta_mercado</th>\n",
       "      <th>beta_size</th>\n",
       "      <th>...</th>\n",
       "      <th>aum</th>\n",
       "      <th>inflow</th>\n",
       "      <th>outflow</th>\n",
       "      <th>shareholders</th>\n",
       "      <th>alavancado</th>\n",
       "      <th>fundo_cotas</th>\n",
       "      <th>fundo_exclusivo</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>-1.593130e-06</td>\n",
       "      <td>1.091729</td>\n",
       "      <td>0.082059</td>\n",
       "      <td>...</td>\n",
       "      <td>9137.31662</td>\n",
       "      <td>81.19231</td>\n",
       "      <td>5581.49185</td>\n",
       "      <td>1097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.08282</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2135</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.003041</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>-1.685012e-06</td>\n",
       "      <td>0.810501</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>...</td>\n",
       "      <td>5050.20479</td>\n",
       "      <td>0.79942</td>\n",
       "      <td>51.73803</td>\n",
       "      <td>69793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.08282</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2283</td>\n",
       "      <td>-0.001030</td>\n",
       "      <td>-0.002219</td>\n",
       "      <td>-0.013564</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>-0.017961</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>-1.637161e-06</td>\n",
       "      <td>0.422152</td>\n",
       "      <td>0.352007</td>\n",
       "      <td>...</td>\n",
       "      <td>1225.94157</td>\n",
       "      <td>0.77860</td>\n",
       "      <td>3.23862</td>\n",
       "      <td>14137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.08282</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2488</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>-4.387408e-06</td>\n",
       "      <td>1.137432</td>\n",
       "      <td>0.033485</td>\n",
       "      <td>...</td>\n",
       "      <td>8513.61482</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>41.46656</td>\n",
       "      <td>24550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.08282</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2526</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.001512</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.001714</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>-9.000344e-07</td>\n",
       "      <td>0.828456</td>\n",
       "      <td>0.210616</td>\n",
       "      <td>...</td>\n",
       "      <td>6503.44172</td>\n",
       "      <td>73.94730</td>\n",
       "      <td>431.82766</td>\n",
       "      <td>102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.08282</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo   dep_var    f_r2_1   f_r12_2  f_st_rev  abnormal_ret  track_error  \\\n",
       "0     744 -0.000282 -0.000076 -0.000614 -0.000152     -0.000999     0.002968   \n",
       "1    2135 -0.000231 -0.000093 -0.003041 -0.000050     -0.003275     0.005959   \n",
       "2    2283 -0.001030 -0.002219 -0.013564 -0.001656     -0.017961     0.014566   \n",
       "3    2488 -0.000113 -0.000131 -0.001530 -0.000105     -0.001925     0.003719   \n",
       "4    2526 -0.000175 -0.000069 -0.001512 -0.000087     -0.001714     0.005033   \n",
       "\n",
       "            MIR  beta_mercado  beta_size  ...         aum    inflow  \\\n",
       "0 -1.593130e-06      1.091729   0.082059  ...  9137.31662  81.19231   \n",
       "1 -1.685012e-06      0.810501   0.012687  ...  5050.20479   0.79942   \n",
       "2 -1.637161e-06      0.422152   0.352007  ...  1225.94157   0.77860   \n",
       "3 -4.387408e-06      1.137432   0.033485  ...  8513.61482   0.00000   \n",
       "4 -9.000344e-07      0.828456   0.210616  ...  6503.44172  73.94730   \n",
       "\n",
       "      outflow  shareholders  alavancado  fundo_cotas  fundo_exclusivo  \\\n",
       "0  5581.49185          1097         0.0          1.0              0.0   \n",
       "1    51.73803         69793         0.0          0.0              0.0   \n",
       "2     3.23862         14137         0.0          0.0              0.0   \n",
       "3    41.46656         24550         0.0          0.0              0.0   \n",
       "4   431.82766           102         0.0          0.0              0.0   \n",
       "\n",
       "        age  year  month  \n",
       "0  31.08282  2011      1  \n",
       "1  31.08282  2011      1  \n",
       "2  31.08282  2011      1  \n",
       "3  31.08282  2011      1  \n",
       "4  31.08282  2011      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664e3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the month and year, create a date column\n",
    "data['date'] = pd.to_datetime([datetime.date(year=y,month=m,day=1) for y, m in zip(data['year'], data['month'])])\n",
    "\n",
    "# Drop NA, reset index, drop the columns containing month and year\n",
    "data = data.dropna().reset_index(drop=True).drop(['month', 'year'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604918f7",
   "metadata": {},
   "source": [
    "# Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad9fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import time # measure time for model to train\n",
    "\n",
    "# Separate train and test dataset into X_train, X_test, y_train, y_test\n",
    "def prepare_train_test(data_train, data_test):\n",
    "    # Separate in dependent and independent variables\n",
    "    y_train, X_train = data_train[['dep_var']], data_train.drop('dep_var', axis = 1)\n",
    "    y_test, X_test = data_test[['dep_var']], data_test.drop('dep_var', axis = 1)\n",
    "\n",
    "    # Reshape the dependente variable\n",
    "    y_train, y_test = y_train.values.ravel(), y_test.values.ravel()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Make any pre-processing needed and fit model and predict\n",
    "def fit_pred_model(model_class, X_train, X_test, y_train, y_test, model_name):\n",
    "    \n",
    "    # These models use distances, so we need to scale our features\n",
    "    if model_name in ['KNeighborsRegressor', 'SVR']:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        \n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Call model\n",
    "    regressor = model_class\n",
    "    \n",
    "    # Fit\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    " \n",
    "# Calculate evaluation metrics for the predictions    \n",
    "def calc_eval_metrics(y_test, y_pred, model_name):\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = True)\n",
    "    \n",
    "    # Create dataframe\n",
    "    metrics_dict = {'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n",
    "    metrics = pd.DataFrame([metrics_dict])\n",
    "    metrics.index = [model_name]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f9c3bd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-01\n",
      "2013-02-01\n",
      "2013-03-01\n",
      "2013-04-01\n",
      "2013-05-01\n",
      "2013-06-01\n",
      "2013-07-01\n",
      "2013-08-01\n",
      "2013-09-01\n",
      "2013-10-01\n",
      "2013-11-01\n",
      "2013-12-01\n"
     ]
    }
   ],
   "source": [
    "# List of models we are going to use\n",
    "models = [LinearRegression(), Lasso(random_state=42), Ridge(random_state=42), \n",
    "          SVR(), KNeighborsRegressor(), DecisionTreeRegressor(random_state=42), \n",
    "          RandomForestRegressor(random_state=42), ExtraTreesRegressor(random_state=42), \n",
    "          AdaBoostRegressor(random_state=42), GradientBoostingRegressor(random_state=42), \n",
    "          DummyRegressor(), XGBRegressor(random_state=42), LGBMRegressor(random_state=42)]\n",
    "\n",
    "metrics_df = pd.DataFrame(columns = ['model_name', 'variable', 'evaluation_metrics', 'date'])\n",
    "for i in range(12):\n",
    "    # Format string to be read as data later\n",
    "    if len(str(i+1)) == 1:\n",
    "        holdout_date = f\"2013-0{i+1}-01\"\n",
    "    else:\n",
    "        holdout_date = f\"2013-{i+1}-01\"\n",
    "        \n",
    "    print(holdout_date)\n",
    "    \n",
    "    # Train = all data before test; Test = specific month\n",
    "    data_train = data.loc[data['date'] < holdout_date].drop(['codigo', 'date'], axis = 1)\n",
    "    data_test = data.loc[data['date'] == holdout_date].drop(['codigo', 'date'], axis = 1)\n",
    "\n",
    "    # Get X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = prepare_train_test(data_train, data_test)\n",
    "    \n",
    "    for model in models: # For each model in our list      \n",
    "        st = time.time() # Start stopwatch\n",
    "        \n",
    "        # Fit and predict\n",
    "        model_pred = fit_pred_model(model, X_train, X_test, y_train, y_test, type(model).__name__)\n",
    "        \n",
    "        et = time.time() # End stopwatch\n",
    "        \n",
    "        # Evaluation metrics\n",
    "        model_df = calc_eval_metrics(y_test, model_pred, type(model).__name__)\n",
    "        \n",
    "        # Add execution time to dataframe\n",
    "        model_df['execution_time'] = et - st\n",
    "        \n",
    "        # Wide to Long\n",
    "        model_df['model_name'] = model_df.index\n",
    "        model_df = pd.melt(model_df, id_vars = 'model_name', \n",
    "                           value_vars = ['MAE', 'MSE', 'RMSE', 'execution_time'], \n",
    "                           value_name = 'evaluation_metrics')\n",
    "        model_df['date'] = holdout_date\n",
    "\n",
    "        metrics_df = pd.concat([metrics_df, model_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74e067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate over metric and model name. Calculate mean and standart deviation\n",
    "metrics_df_gb = metrics_df.drop('date', axis = 1)\n",
    "metrics_df_gb = metrics_df_gb.groupby(by=[\"variable\", 'model_name']).agg(mean=('evaluation_metrics', np.mean),sd=('evaluation_metrics', np.std))\n",
    "# metrics_df_gb = metrics_df_gb.reset_index() # Uncoment for dataframe with data\n",
    "## pd.pivot(metrics_df_gb, index = 'model_name', columns = 'variable', values = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6344f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable  model_name               \n",
       "MAE       RandomForestRegressor        0.000367\n",
       "          GradientBoostingRegressor    0.000368\n",
       "          KNeighborsRegressor          0.000379\n",
       "          ExtraTreesRegressor          0.000381\n",
       "          XGBRegressor                 0.000382\n",
       "          Ridge                        0.000406\n",
       "          LGBMRegressor                0.000420\n",
       "          DecisionTreeRegressor        0.000456\n",
       "          LinearRegression             0.000526\n",
       "          Lasso                        0.000549\n",
       "          DummyRegressor               0.000553\n",
       "          AdaBoostRegressor            0.002434\n",
       "          SVR                          0.076701\n",
       "MSE       RandomForestRegressor        0.003323\n",
       "          ExtraTreesRegressor          0.003377\n",
       "          Ridge                        0.003423\n",
       "          LinearRegression             0.003423\n",
       "          LGBMRegressor                0.003486\n",
       "          GradientBoostingRegressor    0.003503\n",
       "          XGBRegressor                 0.003585\n",
       "          KNeighborsRegressor          0.003617\n",
       "          Lasso                        0.003660\n",
       "          DummyRegressor               0.003660\n",
       "          DecisionTreeRegressor        0.004231\n",
       "          AdaBoostRegressor            0.004830\n",
       "          SVR                          0.076830\n",
       "RMSE      RandomForestRegressor        0.000032\n",
       "          ExtraTreesRegressor          0.000033\n",
       "          LinearRegression             0.000033\n",
       "          GradientBoostingRegressor    0.000033\n",
       "          KNeighborsRegressor          0.000033\n",
       "          Ridge                        0.000034\n",
       "          LGBMRegressor                0.000034\n",
       "          XGBRegressor                 0.000034\n",
       "          Lasso                        0.000035\n",
       "          DummyRegressor               0.000035\n",
       "          DecisionTreeRegressor        0.000038\n",
       "          AdaBoostRegressor            0.000041\n",
       "          SVR                          0.006073\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_gb['mean'].groupby('variable', group_keys=False).apply(lambda x: x.sort_values(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a6a49",
   "metadata": {},
   "source": [
    "# Make Predictions for the remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28efa62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-01-01\n",
      "2014-02-01\n",
      "2014-03-01\n",
      "2014-04-01\n",
      "2014-05-01\n",
      "2014-06-01\n",
      "2014-07-01\n",
      "2014-08-01\n",
      "2014-09-01\n",
      "2014-10-01\n",
      "2014-11-01\n",
      "2014-12-01\n",
      "2015-01-01\n",
      "2015-02-01\n",
      "2015-03-01\n",
      "2015-04-01\n",
      "2015-05-01\n",
      "2015-06-01\n",
      "2015-07-01\n",
      "2015-08-01\n",
      "2015-09-01\n",
      "2015-10-01\n",
      "2015-11-01\n",
      "2015-12-01\n",
      "2016-01-01\n",
      "2016-02-01\n",
      "2016-03-01\n",
      "2016-04-01\n",
      "2016-05-01\n",
      "2016-06-01\n",
      "2016-07-01\n",
      "2016-08-01\n",
      "2016-09-01\n",
      "2016-10-01\n",
      "2016-11-01\n",
      "2016-12-01\n",
      "2017-01-01\n",
      "2017-02-01\n",
      "2017-03-01\n",
      "2017-04-01\n",
      "2017-05-01\n",
      "2017-06-01\n",
      "2017-07-01\n",
      "2017-08-01\n",
      "2017-09-01\n",
      "2017-10-01\n",
      "2017-11-01\n",
      "2017-12-01\n",
      "2018-01-01\n",
      "2018-02-01\n",
      "2018-03-01\n",
      "2018-04-01\n",
      "2018-05-01\n",
      "2018-06-01\n",
      "2018-07-01\n",
      "2018-08-01\n",
      "2018-09-01\n",
      "2018-10-01\n",
      "2018-11-01\n",
      "2018-12-01\n",
      "2019-01-01\n",
      "2019-02-01\n",
      "2019-03-01\n",
      "2019-04-01\n",
      "2019-05-01\n",
      "2019-06-01\n",
      "2019-07-01\n",
      "2019-08-01\n",
      "2019-09-01\n",
      "2019-10-01\n",
      "2019-11-01\n",
      "2019-12-01\n",
      "2020-01-01\n",
      "2020-02-01\n",
      "2020-03-01\n",
      "2020-04-01\n",
      "2020-05-01\n",
      "2020-06-01\n",
      "2020-07-01\n",
      "2020-08-01\n",
      "2020-09-01\n",
      "2020-10-01\n",
      "2020-11-01\n",
      "2020-12-01\n",
      "2021-01-01\n",
      "2021-02-01\n",
      "2021-03-01\n",
      "2021-04-01\n",
      "2021-05-01\n",
      "2021-06-01\n",
      "2021-07-01\n",
      "2021-08-01\n",
      "2021-09-01\n",
      "2021-10-01\n",
      "2021-11-01\n",
      "2021-12-01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 20)) while a minimum of 1 is required by RandomForestRegressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# # Fit and predict\u001b[39;00m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m model_pred \u001b[38;5;241m=\u001b[39m \u001b[43mfit_pred_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m model_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(funds_code, model_pred)), columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunds_code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m model_pred[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m holdout_date\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mfit_pred_model\u001b[1;34m(model_class, X_train, X_test, y_train, y_test, model_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m regressor\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:991\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    989\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 991\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    994\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:605\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    604\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 605\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:909\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 909\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    916\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 20)) while a minimum of 1 is required by RandomForestRegressor."
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(columns = ['funds_code', 'prediction', 'date'])\n",
    "for year in range(2014, 2022): \n",
    "    for month in range(1, 13):\n",
    "        if len(str(month)) == 1:\n",
    "            holdout_date = f\"{str(year)}-0{str(month)}-01\"\n",
    "        else:\n",
    "            holdout_date = f\"{str(year)}-{str(month)}-01\"\n",
    "            \n",
    "        print(holdout_date)\n",
    "            \n",
    "        # Train = all data before test; Test = specific month\n",
    "        data_train = data.loc[data['date'] < holdout_date].drop(['codigo', 'date'], axis = 1)\n",
    "        data_test = data.loc[data['date'] == holdout_date]\n",
    "        \n",
    "        # Save the funds' code\n",
    "        funds_code = data_test['codigo'].to_list()\n",
    "        \n",
    "        # Now we eliminate the two useless columns for the modeling\n",
    "        data_test = data_test.drop(['codigo', 'date'], axis = 1)\n",
    "        \n",
    "        # Get X_train, X_test, y_train, y_test\n",
    "        X_train, X_test, y_train, y_test = prepare_train_test(data_train, data_test)\n",
    "        \n",
    "        # # Fit and predict\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        model_pred = fit_pred_model(model, X_train, X_test, y_train, y_test, type(model).__name__)\n",
    "        \n",
    "        model_pred = pd.DataFrame(list(zip(funds_code, model_pred)), columns = ['funds_code', 'prediction'])\n",
    "        model_pred['date'] = holdout_date\n",
    "        \n",
    "        pred_df = pd.concat([pred_df, model_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d358f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
